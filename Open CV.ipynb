{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"Pictures/Pictures/test.jpg\") #load image\n",
    "cv2.imshow(\"output\", img) #show image\n",
    "cv2.waitKey(0) #wait for exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640) #width\n",
    "cap.set(4, 480) #height\n",
    "cap.set(10, 100) #brightness\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    cv2.imshow(\"video\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "img = cv2.imread(\"Pictures/Pictures/test.jpg\")\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  #coverts color img to gray image (cvtColor)\n",
    "imgBlur = cv2.GaussianBlur(imgGray, (7, 7), 0)  #converts to blur image (odd, odd)\n",
    "imgCanny = cv2.Canny(img, 150, 200) #edge detector\n",
    "imgDialation = cv2.dilate(imgCanny, kernel, iterations = 1)  #increases the thickness\n",
    "imgEroded = cv2.erode(imgDialation, kernel, iterations = 1)  #it reduces the thickness of edges due to dialation\n",
    "                                                             #simply it oposite of dialation\n",
    "\n",
    "cv2.imshow(\"Gray Image\", imgGray)\n",
    "cv2.imshow(\"Blur Image\", imgBlur)\n",
    "cv2.imshow(\"Canny Image\", imgCanny)\n",
    "cv2.imshow(\"Dialation Image\", imgDialation)\n",
    "cv2.imshow(\"Eroded Image\", imgEroded)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n",
      "(200, 300, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "img = cv2.imread(\"Pictures/Pictures/test.jpg\") #load image\n",
    "print(img.shape)\n",
    "\n",
    "imgResize = cv2.resize(img, (300, 200))  #first width then height\n",
    "print(imgResize.shape)\n",
    "\n",
    "imgCropped = img[0:200, 200:500] #first height then width\n",
    "\n",
    "cv2.imshow(\"output\", img) #show image\n",
    "cv2.imshow(\"Resize Image\", imgResize)\n",
    "cv2.imshow(\"Croppes Image\", imgCropped)\n",
    "cv2.waitKey(0) #wait for exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = np.zeros((512,512,3),np.uint8)  #zero means black #grayscale image [np.uint8] give values from 0-255\n",
    "#print(img)\n",
    "#img[:] = 255,0,0 #color img\n",
    "\n",
    "cv2.line(img, (0,0), (512,512), (0,255,0), 3) #draws line [origin, end, color, thickness] of line[end=img.shape[1],img.shape[0]]\n",
    "cv2.rectangle(img, (0,0), (200,300), (0,0,250), cv2.FILLED) #draws line [origin, end, color, thickness] of rectangle\n",
    "cv2.circle(img, (400,300), 50, (255,255,0), cv2.FILLED) #circle [center, radius, color]\n",
    "cv2.putText(img, \"OPEN CV\", (300, 200),cv2.FONT_HERSHEY_COMPLEX, 1, (0,150,0),1) #put text on img\n",
    "\n",
    "#warp image\n",
    "width, height = 200, 300\n",
    "pts1 = np.float32([[0,0],[200,0],[0,300],[200,300]])\n",
    "pts2 = np.float32([[0,0],[width,0],[0,height],[width,height]])\n",
    "matrix = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "imgOutput = cv2.warpPerspective(img, matrix, (width, height))\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"Image Output\", imgOutput)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"Pictures/Pictures/test.jpg\") #load image\n",
    "hor = np.hstack((img,img)) #joining images\n",
    "ver = np.vstack((img,img))\n",
    "cv2.imshow(\"Horizontal\", hor)\n",
    "cv2.imshow(\"Vertical\", ver)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#color detection\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def empty(a):\n",
    "    pass\n",
    "\n",
    " #load image\n",
    "cv2.namedWindow(\"TrackBars\")\n",
    "cv2.resizeWindow(\"TrackBars\", 640, 240)\n",
    "cv2.createTrackbar(\"Hue Min\", \"TrackBars\", 0, 179, empty)       \n",
    "cv2.createTrackbar(\"Hue Max\", \"TrackBars\", 60, 179, empty)\n",
    "cv2.createTrackbar(\"Sat Min\", \"TrackBars\", 0, 255, empty)\n",
    "cv2.createTrackbar(\"Sat Max\", \"TrackBars\", 255, 255, empty)\n",
    "cv2.createTrackbar(\"Val Min\", \"TrackBars\", 35, 255, empty)\n",
    "cv2.createTrackbar(\"Val Max\", \"TrackBars\", 156, 255, empty)\n",
    "\n",
    "while True:\n",
    "    img = cv2.imread(\"Pictures/Pictures/test.jpg\")\n",
    "    imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    h_min = cv2.getTrackbarPos(\"Hue Min\", \"TrackBars\")\n",
    "    h_max = cv2.getTrackbarPos(\"Hue Max\", \"TrackBars\")\n",
    "    s_min = cv2.getTrackbarPos(\"Sat Min\", \"TrackBars\")\n",
    "    s_max = cv2.getTrackbarPos(\"Sat Max\", \"TrackBars\")\n",
    "    v_min = cv2.getTrackbarPos(\"Val Min\", \"TrackBars\")\n",
    "    v_max = cv2.getTrackbarPos(\"Val Max\", \"TrackBars\")\n",
    "   # print(h_min, h_max, s_min, s_max, v_min, v_max)\n",
    "    \n",
    "    lower = np.array([h_min, s_min, v_min])\n",
    "    upper = np.array([h_max, s_max, v_max])\n",
    "    mask = cv2.inRange(imgHSV, lower, upper)\n",
    "    imgResult = cv2.bitwise_and(img, img, mask = mask)\n",
    "    \n",
    "    cv2.imshow(\"Image\", img) #show image\n",
    "    cv2.imshow(\"imgHSV\", imgHSV)\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "    cv2.imshow(\"Result\", imgResult)\n",
    "    cv2.waitKey(0) #wait for exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3123.5\n",
      "8\n",
      "8555.0\n",
      "4\n",
      "10404.0\n",
      "4\n",
      "10190.0\n",
      "8\n",
      "0.5\n",
      "1.0\n",
      "1.0\n",
      "0.5\n",
      "1579.0\n",
      "3\n",
      "10404.0\n",
      "4\n",
      "1.0\n",
      "19578.5\n",
      "4\n",
      "19712.0\n",
      "4\n",
      "1.5\n",
      "3481.0\n",
      "4\n",
      "2277.0\n",
      "4\n",
      "1.0\n",
      "19852.0\n",
      "4\n",
      "19997.0\n",
      "4\n",
      "1.0\n",
      "0.0\n",
      "1.5\n",
      "1.5\n",
      "2159.0\n",
      "4\n",
      "0.5\n",
      "110.5\n",
      "1.5\n",
      "10238.0\n",
      "8\n",
      "5662.5\n",
      "3\n",
      "0.5\n",
      "1.0\n",
      "1.0\n",
      "0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def getContours(img):\n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        print(area)\n",
    "        if area>500:\n",
    "            cv2.drawContours(imgContour, cnt, -1, (255,0,0), 3)\n",
    "            peri = cv2.arcLength(cnt, True)\n",
    "            #print(peri)\n",
    "            approx = cv2.approxPolyDP(cnt, 0.02*peri, True)\n",
    "            print(len(approx))\n",
    "            objcor = len(approx)\n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    "            \n",
    "            \n",
    "            if objcor == 3: objectType = \"Tri\"\n",
    "            elif objcor == 4:\n",
    "                aspRatio = w/float(h)\n",
    "                if aspRatio > 0.95 and aspRatio < 1.05: objectType = \"Square\"\n",
    "                else: objectType = \"Rectangle\"\n",
    "            elif objcor > 4: objectType = \"Circle\"\n",
    "            else: objectType = \"None\"\n",
    "                \n",
    "            cv2.rectangle(imgContour, (x,y), (x+w, y+h), (0,255,0),2)\n",
    "            cv2.putText(imgContour, objectType,\n",
    "                           (x+(w//2)-10, y+(h//2)-10), cv2.FONT_HERSHEY_COMPLEX,0.5,\n",
    "                           (0,0,0),2)\n",
    "        \n",
    "\n",
    "\n",
    "img = cv2.imread(\"Pictures/Pictures/shape.png\")\n",
    "imgContour = img.copy()\n",
    "\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  #coverts color img to gray image (cvtColor)\n",
    "imgBlur = cv2.GaussianBlur(imgGray, (7, 7), 1)\n",
    "imgCanny = cv2.Canny(imgBlur, 50, 50)\n",
    "getContours(imgCanny)\n",
    "\n",
    "\n",
    "cv2.imshow(\"output\", img)\n",
    "cv2.imshow(\"Gray\", imgGray) \n",
    "cv2.imshow(\"Blur\", imgBlur)\n",
    "cv2.imshow(\"Canny\", imgCanny)\n",
    "cv2.imshow(\"imgContour\", imgContour)\n",
    "cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(\"Pictures/Pictures/haarcascade_frontalface_default.xml\")\n",
    "img = cv2.imread(\"Pictures/Pictures/test.jpg\")\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = faceCascade.detectMultiScale(imgGray, 1.1, 4)\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img, (x,y,),(x+w,y+h), (255,0,0), 2)\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow(\"output\", img) #show image\n",
    "cv2.waitKey(0) #wait for exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COLOR DECTECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 600) #width\n",
    "cap.set(4, 500) #height\n",
    "cap.set(10, 100) #brightness\n",
    "\n",
    "myColors = [[5,107,0,19,255,255],\n",
    "            [133,56,0,159,156,255],\n",
    "            [57,76,0,100,255,255],\n",
    "            [90,48,0,118,255,255]]\n",
    "\n",
    "myColorValues = [[51,153,255],    #BGR\n",
    "                 [255,0,255],\n",
    "                 [0,255,0],\n",
    "                 [255,0,0]]\n",
    "\n",
    "myPoints = [] #[x,y,color]\n",
    "\n",
    "\n",
    "def findColor(img,myColors,myColorValues):\n",
    "    imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    count = 0\n",
    "    newPoints = []\n",
    "    for color in myColors:\n",
    "        lower = np.array(color[0:3])\n",
    "        upper = np.array(color[3:6])\n",
    "        mask = cv2.inRange(imgHSV, lower, upper)\n",
    "        #cv2.imshow(str(color[0]), mask)\n",
    "        x,y = getContours(mask)\n",
    "        cv2.circle(imgResult,(x,y), 10, myColorValues[count],cv2.FILLED)\n",
    "        if x!=0 and y!=0:\n",
    "            newPoints.append([x,y,count])\n",
    "        count += 1\n",
    "    return newPoints\n",
    "    \n",
    "def getContours(img):\n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    x,y,w,h = 0,0,0,0\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area>500:\n",
    "            #cv2.drawContours(imgResult, cnt, -1, (255,0,0), 3)\n",
    "            peri = cv2.arcLength(cnt, True)\n",
    "            approx = cv2.approxPolyDP(cnt, 0.02*peri, True)\n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    "    return x+w//2,y\n",
    "\n",
    "def drawOnCanvas(myPoints,myColorValues):\n",
    "    for point in myPoints:\n",
    "        cv2.circle(imgResult,(point[0],point[1]), 10, myColorValues[point[2]],cv2.FILLED)\n",
    "\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    imgResult = img.copy()\n",
    "    newPoints = findColor(img,myColors,myColorValues)\n",
    "    if len(newPoints) != 0:\n",
    "        for newP in newPoints:\n",
    "            myPoints.append(newP)\n",
    "    if len(newPoints) !=0 :\n",
    "        drawOnCanvas(myPoints,myColorValues)\n",
    "    cv2.imshow(\"Result\", imgResult)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 0 into shape (4,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8aa1745f0276>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mbiggest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgThres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;31m#print(biggest)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[0mimgWrapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetWrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbiggest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Result\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgWrapped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-8aa1745f0276>\u001b[0m in \u001b[0;36mgetWrap\u001b[1;34m(img, biggest)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetWrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbiggest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;31m#warp image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[0mbigest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreorder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbiggest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mpts1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbiggest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-8aa1745f0276>\u001b[0m in \u001b[0;36mreorder\u001b[1;34m(myPoints)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mreorder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyPoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mmyPoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmyPoints\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[0mmyPointsNew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0madd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmyPoints\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (4,2)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 740) #width\n",
    "cap.set(4, 580) #height\n",
    "cap.set(10, 150) #brightness\n",
    "\n",
    "widthImg = 640 \n",
    "heightImg = 480\n",
    "\n",
    "\n",
    "def preProcessing(img):\n",
    "    imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    imgBlur = cv2.GaussianBlur(imgGray, (5, 5), 1)  #converts to blur image (odd, odd)\n",
    "    imgCanny = cv2.Canny(img, 200, 200) #edge detector\n",
    "    kernel = np.ones((5,5))\n",
    "    imgDial = cv2.dilate(imgCanny, kernel, iterations = 2)  #increases the thickness\n",
    "    imgThres = cv2.erode(imgDial, kernel, iterations = 1)\n",
    "    \n",
    "    return imgThres\n",
    "\n",
    "def getContours(img):\n",
    "    biggest = np.array([])\n",
    "    maxArea = 0\n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area>500:\n",
    "            #cv2.drawContours(imgContour, cnt, -1, (255,0,0), 3)\n",
    "            peri = cv2.arcLength(cnt, True)\n",
    "            approx = cv2.approxPolyDP(cnt, 0.02*peri, True)\n",
    "            if area > maxArea and len(approx) == 4:\n",
    "                biggest = approx\n",
    "                maxArea = area\n",
    "    cv2.drawContours(imgContour, biggest, -1, (255,0,0), 20)\n",
    "    return biggest\n",
    "\n",
    "def reorder(myPoints):\n",
    "    myPoints = myPoints.reshape((4,2))\n",
    "    myPointsNew = np.zeros((4,1,2),np.int32)\n",
    "    add = myPoints.sum(1)\n",
    "    #print(\"add\", add)\n",
    "    \n",
    "    myPointsNew[0] = myPoints[np.argmin(add)]\n",
    "    myPointsNew[3] = myPoints[np.argmax(add)]\n",
    "   \n",
    "    \n",
    "    diff = np.diff(myPoints, axis = 1)\n",
    "    myPointsNew[1] = myPoints[np.argmin(diff)]\n",
    "    myPointsNew[2] = myPoints[np.argmax(diff)]\n",
    "    #print(\"My points\", myPointsNew)\n",
    "    return myPointsNew\n",
    "\n",
    "def getWrap(img,biggest):\n",
    "    #warp image\n",
    "    bigest = reorder(biggest)\n",
    "    width, height = 200, 300\n",
    "    pts1 = np.float32(biggest)\n",
    "    pts2 = np.float32([[0,0],[widthImg,0],[0,heightImg],[widthImg,heightImg]])\n",
    "    matrix = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "    imgOutput = cv2.warpPerspective(img, matrix, (widthImg, heightImg))\n",
    "    \n",
    "    return imgOutput\n",
    "\n",
    "    \n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    cv2.resize(img,(widthImg, heightImg))\n",
    "    imgContour = img.copy()\n",
    "    imgThres = preProcessing(img)\n",
    "    biggest = getContours(imgThres)\n",
    "    #print(biggest)\n",
    "    imgWrapped = getWrap(img,biggest)\n",
    "    \n",
    "    cv2.imshow(\"Result\", imgWrapped)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "###################################\n",
    "widthImg=540\n",
    "heightImg =640\n",
    "#####################################\n",
    " \n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(10,150)\n",
    " \n",
    "def preProcessing(img):\n",
    "    imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    imgBlur = cv2.GaussianBlur(imgGray,(5,5),1)\n",
    "    imgCanny = cv2.Canny(imgBlur,200,200)\n",
    "    kernel = np.ones((5,5))\n",
    "    imgDial = cv2.dilate(imgCanny,kernel,iterations=2)\n",
    "    imgThres = cv2.erode(imgDial,kernel,iterations=1)\n",
    "    return imgThres\n",
    " \n",
    "def getContours(img):\n",
    "    biggest = np.array([])\n",
    "    maxArea = 0\n",
    "    contours,hierarchy = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area>500:\n",
    "            #cv2.drawContours(imgContour, cnt, -1, (255, 0, 0), 3)\n",
    "            peri = cv2.arcLength(cnt,True)\n",
    "            approx = cv2.approxPolyDP(cnt,0.02*peri,True)\n",
    "            if area >maxArea and len(approx) == 4:\n",
    "                biggest = approx\n",
    "                maxArea = area\n",
    "    cv2.drawContours(imgContour, biggest, -1, (255, 0, 0), 20)\n",
    "    return biggest\n",
    " \n",
    "def reorder (myPoints):\n",
    "    myPoints = myPoints.reshape((4,2))\n",
    "    myPointsNew = np.zeros((4,1,2),np.int32)\n",
    "    add = myPoints.sum(1)\n",
    "    #print(\"add\", add)\n",
    "    myPointsNew[0] = myPoints[np.argmin(add)]\n",
    "    myPointsNew[3] = myPoints[np.argmax(add)]\n",
    "    diff = np.diff(myPoints,axis=1)\n",
    "    myPointsNew[1]= myPoints[np.argmin(diff)]\n",
    "    myPointsNew[2] = myPoints[np.argmax(diff)]\n",
    "    #print(\"NewPoints\",myPointsNew)\n",
    "    return myPointsNew\n",
    " \n",
    "def getWarp(img,biggest):\n",
    "    biggest = reorder(biggest)\n",
    "    pts1 = np.float32(biggest)\n",
    "    pts2 = np.float32([[0, 0], [widthImg, 0], [0, heightImg], [widthImg, heightImg]])\n",
    "    matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    imgOutput = cv2.warpPerspective(img, matrix, (widthImg, heightImg))\n",
    " \n",
    "    imgCropped = imgOutput[20:imgOutput.shape[0]-20,20:imgOutput.shape[1]-20]\n",
    "    imgCropped = cv2.resize(imgCropped,(widthImg,heightImg))\n",
    " \n",
    "    return imgCropped\n",
    " \n",
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver\n",
    " \n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    img = cv2.resize(img,(widthImg,heightImg))\n",
    "    imgContour = img.copy()\n",
    " \n",
    "    imgThres = preProcessing(img)\n",
    "    biggest = getContours(imgThres)\n",
    "    if biggest.size !=0:\n",
    "        imgWarped=getWarp(img,biggest)\n",
    "        # imageArray = ([img,imgThres],\n",
    "        #           [imgContour,imgWarped])\n",
    "        imageArray = ([imgContour, imgWarped])\n",
    "        cv2.imshow(\"ImageWarped\", imgWarped)\n",
    "    else:\n",
    "        # imageArray = ([img, imgThres],\n",
    "        #               [img, img])\n",
    "        imageArray = ([imgContour, img])\n",
    " \n",
    "    stackedImages = stackImages(0.6,imageArray)\n",
    "    cv2.imshow(\"WorkFlow\", stackedImages)\n",
    " \n",
    "    if cv2.waitKey(1) and 0xFF == ord('q'):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NUMBER PLATE DETECTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imgRoi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-27f4db14f96a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;36m0xFF\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m's'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m#cv2.imwrite(\"Pictures/Pictures\"+str(count)+\".jpg\",imgRoi)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Pictures/Pictures\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".jpg\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimgRoi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m640\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFILLED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         cv2.putText(img,\"Scan Saved\",(150,265),\n",
      "\u001b[1;31mNameError\u001b[0m: name 'imgRoi' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "count = 0\n",
    "nplateCascade = cv2.CascadeClassifier(\"Pictures/Pictures/haarcascade_russian_plate_number.xml\")\n",
    "color =  255, 0, 255\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640) #width\n",
    "cap.set(4, 480) #height\n",
    "cap.set(10, 100) #brightness\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    \n",
    "    imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    numberPlates = nplateCascade.detectMultiScale(imgGray, 1.1, 4)\n",
    "\n",
    "    for (x,y,w,h) in numberPlates:\n",
    "        area = w * h\n",
    "        \n",
    "        if area > 500:\n",
    "            cv2.rectangle(img, (x,y,),(x+w,y+h), (255,0,255), 2)\n",
    "            cv2.putText(img,\"Number PLate\",(x, y-5),\n",
    "                       cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, color, 2)\n",
    "            imRoi = img[y:y+h, x:x+w]\n",
    "            cv2.imshow(\"ROI\", imRoi)\n",
    "    \n",
    "    cv2.imshow(\"video\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "        #cv2.imwrite(\"Pictures/Pictures\"+str(count)+\".jpg\",imgRoi)\n",
    "        cv2.imwrite(\"Pictures/Pictures\"+str(count)+\".jpg\",imgRoi)\n",
    "        cv2.rectangle(img,(0,200),(640,300),(0,255,0),cv2.FILLED)\n",
    "        cv2.putText(img,\"Scan Saved\",(150,265),\n",
    "                       cv2.FONT_HERSHEY_COMPLEX_SMALL, 2, (0,0,255) , 2)\n",
    "        cv2.imshow(\"Result\",img)\n",
    "        cv2.waitKey(500)\n",
    "        count += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    " \n",
    "frameWidth = 640\n",
    "frameHeight = 480\n",
    "nPlateCascade = cv2.CascadeClassifier(\"Pictures/Pictures/haarcascade_russian_plate_number.xml\")\n",
    "minArea = 200\n",
    "color = (255,0,255)\n",
    "\n",
    " \n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, frameWidth)\n",
    "cap.set(4, frameHeight)\n",
    "cap.set(10,150)\n",
    "count = 0\n",
    " \n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    numberPlates = nPlateCascade.detectMultiScale(imgGray, 1.1, 10)\n",
    "    for (x, y, w, h) in numberPlates:\n",
    "        area = w*h\n",
    "        if area >minArea:\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 255), 2)\n",
    "            cv2.putText(img,\"Number Plate\",(x,y-5),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX_SMALL,1,color,2)\n",
    "            imgRoi = img[y:y+h,x:x+w]\n",
    "            cv2.imshow(\"ROI\", imgRoi)\n",
    " \n",
    "    cv2.imshow(\"Result\", img)\n",
    " \n",
    "    if cv2.waitKey(1) and 0xFF == ord('s'):\n",
    "        cv2.imwrite(\"Pictures/Pictures\"+str(count)+\".jpg\",imgRoi)\n",
    "        cv2.rectangle(img,(0,200),(640,300),(0,255,0),cv2.FILLED)\n",
    "        cv2.putText(img,\"Scan Saved\",(150,265),cv2.FONT_HERSHEY_DUPLEX,\n",
    "                    2,(0,0,255),2)\n",
    "        cv2.imshow(\"Result\",img)\n",
    "        cv2.waitKey(500)\n",
    "        count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
